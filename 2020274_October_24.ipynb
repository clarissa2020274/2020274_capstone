{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f1b685",
   "metadata": {},
   "source": [
    "## MSc Data Analytics - Capstone Project\n",
    "\n",
    "#### Predictive Insights in the Coffee Market: Time Series Models for forecasting coffee prices\n",
    "\n",
    "Student id: 2020274 Clarissa Cardoso\n",
    "\n",
    "Introduction\n",
    "This capstone project aims to apply different time series models to forecast the prices of coffee in the commodity stock market. \n",
    "Central to this analysis is the ICO Composite Indicator Price (I-CIP), which is a critical benchmark reflecting global coffee market trends. \n",
    "Accurate forecasting of the I-CIP is vital for stakeholders throughout the coffee industry, from producers to investors. \n",
    "\n",
    "\n",
    "The data utilized in this project is sourced from the International Coffee Organization's (ICO) Public Market Information, which provides the I-CIP values free of charge.\n",
    "\n",
    "For the early stages of this experimentation, 1 year worth of data was available to collect, from 01Feb23 to 29Feb24.\n",
    "\n",
    "Objectives:\n",
    "Model Building: Develop and evaluate various time series forecasting models to predict future values of the I-CIP.\n",
    "\n",
    "\n",
    "        Model Development: build and train various time series forecasting models, including traditional statistical models (e.g., ARIMA/Sarima) and machine learning algorithms (e.g., LSTM neural networks).\n",
    "        Model Evaluation: evaluate the performance of each model using appropriate metrics, such as mean absolute error (MAE) and root mean squared error (RMSE), to determine their predictive accuracy.\n",
    "        Forecasting: generate forecasts for future I-CIP values using the best-performing model(s) and visualize the results to facilitate interpretation and decision-making.\n",
    "- 1 day\n",
    "- 5 days = 1 week\n",
    "- 21 days = 1 month\n",
    "(- 63 days = 3 months (1 quarter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c486ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras version: 2.10.0\n",
      "TensorFlow version: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "\n",
    "## cheking if keras/tensorflow are correclty installed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd396c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd #dataframes \n",
    "import numpy as np #linear algebra\n",
    "import seaborn as sns #visualization\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "import scipy.stats as stats #statistical resources\n",
    "\n",
    "import matplotlib.pyplot as plt #visualisation \n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn.model_selection import train_test_split # importing function to split the data training and test.\n",
    "from sklearn.preprocessing import MinMaxScaler # Import the MinMaxScaler module from sklearn.preprocessing library\n",
    "from sklearn.linear_model import LinearRegression # importing to performe linear regression. \n",
    "from sklearn.metrics import make_scorer, r2_score # Importing from Metrics module\n",
    "from sklearn.preprocessing import StandardScaler # standardize the data\n",
    "from sklearn import metrics # Metrics module from scikit-learn\n",
    "from sklearn.model_selection import GridSearchCV # importing for hyperparameter tunning\n",
    "from sklearn.metrics import mean_squared_error # importing mse\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential #last update in python causing dead kernel wehn importing keras functions?\n",
    "from keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e8f09",
   "metadata": {},
   "source": [
    "# 1. Load data\n",
    "\n",
    "For the early stages of this experimentation, 1 year worth of data was available to collect, from 01Feb23 to 29Feb24.\n",
    "\n",
    "This section will review the original dataset compiled with data from feb 23 to feb 24.\n",
    "\n",
    "\n",
    "Since then, ICO has released additional months that will be included in the dataframe.\n",
    "\n",
    "A few thingsobserved when importing the raw files: \n",
    "\n",
    "- Column mismatch: Assuming all files have the same column names and order. This can lead to errors when merging DataFrames with different structures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f331a3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import files from directory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb4ea12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d00ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d52b5d1",
   "metadata": {},
   "source": [
    "# 2. Data preparation/EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f07ea",
   "metadata": {},
   "source": [
    "# 3. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dec94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
